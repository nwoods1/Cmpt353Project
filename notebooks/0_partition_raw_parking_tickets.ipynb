{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d636304",
   "metadata": {},
   "source": [
    "# Partition Raw Parking Ticket Data\n",
    "The raw parking ticket data is too large to be uploaded into the shared Github repository, so instead, we will shard it into smaller files and compress the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "max_file_size = 4 * 1024 * 1024 # 4 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9b9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"../data/raw_data/parking-tickets.csv\"\n",
    "out_dir = \"../data/raw_data/parking_tickets\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_file_prefix = \"parking_tickets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c3c79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Block</th>\n",
       "      <th>Street</th>\n",
       "      <th>EntryDate</th>\n",
       "      <th>Bylaw</th>\n",
       "      <th>Section</th>\n",
       "      <th>Status</th>\n",
       "      <th>InfractionText</th>\n",
       "      <th>Year</th>\n",
       "      <th>BI_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100</td>\n",
       "      <td>DAVIE ST</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(B)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE TIME RECORDED B...</td>\n",
       "      <td>2023</td>\n",
       "      <td>4487040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500</td>\n",
       "      <td>COAL HARBOUR QUAY</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(A)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2023</td>\n",
       "      <td>4487044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500</td>\n",
       "      <td>COAL HARBOUR QUAY</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(A)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2023</td>\n",
       "      <td>4487045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>ROBSON ST</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(A)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2023</td>\n",
       "      <td>4487049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100</td>\n",
       "      <td>ROBSON ST</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>2952</td>\n",
       "      <td>5(4)(A)(ii)</td>\n",
       "      <td>IS</td>\n",
       "      <td>PARK IN A METERED SPACE IF THE PARKING METER H...</td>\n",
       "      <td>2023</td>\n",
       "      <td>4487050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Block             Street   EntryDate  Bylaw      Section Status  \\\n",
       "0   1100           DAVIE ST  2023-05-01   2952      5(4)(B)     IS   \n",
       "1   1500  COAL HARBOUR QUAY  2023-05-01   2952  5(4)(A)(ii)     IS   \n",
       "2   1500  COAL HARBOUR QUAY  2023-05-01   2952  5(4)(A)(ii)     IS   \n",
       "3   1000          ROBSON ST  2023-05-01   2952  5(4)(A)(ii)     IS   \n",
       "4   1100          ROBSON ST  2023-05-01   2952  5(4)(A)(ii)     IS   \n",
       "\n",
       "                                      InfractionText  Year    BI_ID  \n",
       "0  PARK IN A METERED SPACE IF THE TIME RECORDED B...  2023  4487040  \n",
       "1  PARK IN A METERED SPACE IF THE PARKING METER H...  2023  4487044  \n",
       "2  PARK IN A METERED SPACE IF THE PARKING METER H...  2023  4487045  \n",
       "3  PARK IN A METERED SPACE IF THE PARKING METER H...  2023  4487049  \n",
       "4  PARK IN A METERED SPACE IF THE PARKING METER H...  2023  4487050  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(in_file, sep=\";\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a6e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_1.json.gz — 3.79 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_2.json.gz — 3.91 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_3.json.gz — 3.89 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_4.json.gz — 3.98 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_5.json.gz — 3.94 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_6.json.gz — 3.59 MB, 300000 rows\n",
      "Wrote ../data/raw_data/parking_tickets/parking_tickets_7.json.gz — 2.72 MB, 220593 rows\n"
     ]
    }
   ],
   "source": [
    "chunk_index = 1\n",
    "rows_written = 0\n",
    "while rows_written < len(df):\n",
    "    step = 300000  # starting guess of 300,000 rows per chunk\n",
    "\n",
    "    while True:\n",
    "        chunk_df = df.iloc[rows_written:rows_written + step]\n",
    "        temp_path = os.path.join(out_dir, f\"temp_chunk.json.gz\")\n",
    "\n",
    "        # Write to temporary file using pandas\n",
    "        chunk_df.to_json(temp_path, orient=\"records\", lines=True, compression=\"gzip\")\n",
    "\n",
    "        file_size = os.path.getsize(temp_path)\n",
    "        if file_size <= max_file_size or step <= 100:\n",
    "            break\n",
    "        step = int(step * 0.8)  # shrink the chunk size\n",
    "\n",
    "    # Rename temp file to final name\n",
    "    final_path = os.path.join(out_dir, f\"{out_file_prefix}_{chunk_index}.json.gz\")\n",
    "    os.rename(temp_path, final_path)\n",
    "\n",
    "    print(f\"Wrote {final_path} — {file_size / (1024 * 1024):.2f} MB, {len(chunk_df)} rows\")\n",
    "\n",
    "    rows_written += len(chunk_df)\n",
    "    chunk_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4b9da",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4588aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed data matches original!\n"
     ]
    }
   ],
   "source": [
    "chunked_files = sorted([f for f in os.listdir(out_dir) if f.endswith(\".json.gz\")])\n",
    "reconstructed_df = pd.concat([\n",
    "    pd.read_json(os.path.join(out_dir, f), orient='records', lines=True)\n",
    "    for f in chunked_files\n",
    "], ignore_index=True)\n",
    "\n",
    "equal = df.equals(reconstructed_df)\n",
    "\n",
    "if equal:\n",
    "    print(\"Reconstructed data matches original!\")\n",
    "else:\n",
    "    diff_count = (df != reconstructed_df).sum().sum()\n",
    "    print(f\"Data mismatch detected ({diff_count} differing values).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
